# sqrt_mse <- (mean(split_obj$error^2))^.5
ggreg_error_vec <- map_dbl(split_obj$error, 1)
ggreg_error_vec <- map_dbl(split_obj$error, 1)
ggreg_error_vec
sqrt_mse_ggreg <- (mean(ggreg_error_vec^2))^.5
sqrt_mse_simple <- (mean(simple_error_vec^2))^.5
simple_error_vec <- map_dbl(split_obj$error, 2)
sqrt_mse_ggreg
sqrt_mse_simple
sqrt_mse_simple <- (mean(simple_error_vec^2))^.5
sqrt_mse_simple
# Create new variables and drop everything else
kids <- ihds %>%
filter(!is.na(TA8B)) %>%
transmute(ASER4, TA4, RO3, URBAN2011, ASSETS, log_inc = log(INCOME+1), group = as_factor(GROUPS), RO5, HHEDUC, NPERSONS, log_pcc = log(COPC), private = ifelse((CS4 ==4), 1, 0))
rx <- as.formula("ASER4 ~ TA4 + log_pcc + RO3 + RO5 + HHEDUC + private + NPERSONS + URBAN2011 + log_inc + group")
rho <- 20
split_obj <- vfold_cv(kids, v = rho, repeats = 5)
# Calculate the true overall mean
true <- mean(kids$ASER4)
ggreg_error <- function(splits){
# note that I treat the assessment data as the training data.
# this is because I want to fit the data on the 1/rho share of the data that is in the assessment data
sample <- assessment(splits)
other <- analysis(splits)
mod <- glm(rx, data = sample, family = binomial(link = "probit"))
#mod <- lm(rx, data = sample)
# fit the model to both the sample and the rest of the data
preds_other <- augment(mod, newdata = other, type.predict = "response")
preds_sample <- augment(mod, newdata = sample, type.predict = "response")
# Calculate the generalized GREG (see Pfefferman eq 4.8 for details)
ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE)/rho - mean(preds_sample$.fitted, na.rm = TRUE)/rho
# ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE) - mean(preds_sample$.fitted, na.rm = TRUE)
return(list(true-ggreg, true- mean(sample$ASER4, na.rm=TRUE)))
}
split_obj$error <- map(split_obj$splits, ggreg_error)
ggreg_error_vec <- map_dbl(split_obj$error, 1)
simple_error_vec <- map_dbl(split_obj$error, 2)
sqrt_mse_ggreg <- (mean(ggreg_error_vec^2))^.5
sqrt_mse_ggreg
sqrt_mse_simple <- (mean(simple_error_vec^2))^.5
sqrt_mse_simple
# Create new variables and drop everything else
kids <- ihds %>%
filter(!is.na(TA8B)) %>%
transmute(ASER4, TA4, RO3, URBAN2011, ASSETS, log_inc = log(INCOME+1), group = as_factor(GROUPS), RO5, HHEDUC, NPERSONS, log_pcc = log(COPC), private = ifelse((CS4 ==4), 1, 0))
rx <- as.formula("ASER4 ~ TA4 + log_pcc + RO3 + RO5 + HHEDUC + private + NPERSONS + URBAN2011 + log_inc + group")
rho <- 20
split_obj <- vfold_cv(kids, v = rho, repeats = 10)
# Calculate the true overall mean
true <- mean(kids$ASER4)
ggreg_error <- function(splits){
# note that I treat the assessment data as the training data.
# this is because I want to fit the data on the 1/rho share of the data that is in the assessment data
sample <- assessment(splits)
other <- analysis(splits)
mod <- glm(rx, data = sample, family = binomial(link = "probit"))
#mod <- lm(rx, data = sample)
# fit the model to both the sample and the rest of the data
preds_other <- augment(mod, newdata = other, type.predict = "response")
preds_sample <- augment(mod, newdata = sample, type.predict = "response")
# Calculate the generalized GREG (see Pfefferman eq 4.8 for details)
ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE)/rho - mean(preds_sample$.fitted, na.rm = TRUE)/rho
# ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE) - mean(preds_sample$.fitted, na.rm = TRUE)
return(list(true-ggreg, true- mean(sample$ASER4, na.rm=TRUE)))
}
split_obj$error <- map(split_obj$splits, ggreg_error)
ggreg_error_vec <- map_dbl(split_obj$error, 1)
simple_error_vec <- map_dbl(split_obj$error, 2)
sqrt_mse_ggreg <- (mean(ggreg_error_vec^2))^.5
sqrt_mse_ggreg
sqrt_mse_simple <- (mean(simple_error_vec^2))^.5
sqrt_mse_simple
# Create new variables and drop everything else
kids <- ihds %>%
filter(!is.na(TA8B)) %>%
transmute(ASER4, TA4, RO3, URBAN2011, ASSETS, log_inc = log(INCOME+1), group = as_factor(GROUPS), RO5, HHEDUC, NPERSONS, log_pcc = log(COPC), private = ifelse((CS4 ==4), 1, 0))
rx <- as.formula("ASER4 ~ TA4 + log_pcc + RO3 + RO5 + HHEDUC + private + NPERSONS + URBAN2011 + log_inc + group")
rho <- 10
set.seed(8675309)
split_obj <- vfold_cv(kids, v = rho, repeats = 10)
# Calculate the true overall mean
true <- mean(kids$ASER4)
ggreg_error <- function(splits){
# note that I treat the assessment data as the training data.
# this is because I want to fit the data on the 1/rho share of the data that is in the assessment data
sample <- assessment(splits)
other <- analysis(splits)
mod <- glm(rx, data = sample, family = binomial(link = "probit"))
#mod <- lm(rx, data = sample)
# fit the model to both the sample and the rest of the data
preds_other <- augment(mod, newdata = other, type.predict = "response")
preds_sample <- augment(mod, newdata = sample, type.predict = "response")
# Calculate the generalized GREG (see Pfefferman eq 4.8 for details)
ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE)/rho - mean(preds_sample$.fitted, na.rm = TRUE)/rho
# ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE) - mean(preds_sample$.fitted, na.rm = TRUE)
return(list(true-ggreg, true- mean(sample$ASER4, na.rm=TRUE)))
}
split_obj$error <- map(split_obj$splits, ggreg_error)
ggreg_error_vec <- map_dbl(split_obj$error, 1)
simple_error_vec <- map_dbl(split_obj$error, 2)
sqrt_mse_ggreg <- (mean(ggreg_error_vec^2))^.5
sqrt_mse_ggreg
sqrt_mse_simple <- (mean(simple_error_vec^2))^.5
sqrt_mse_simple
# Create new variables and drop everything else
kids <- ihds %>%
filter(!is.na(TA8B)) %>%
transmute(ASER4, TA4, RO3, URBAN2011, ASSETS, log_inc = log(INCOME+1), group = as_factor(GROUPS), RO5, HHEDUC, NPERSONS, log_pcc = log(COPC), private = ifelse((CS4 ==4), 1, 0))
rx <- as.formula("ASER4 ~ TA4 + log_pcc + RO3 + RO5 + HHEDUC + private + NPERSONS + URBAN2011 + log_inc + group")
rho <- 10
set.seed(123)
split_obj <- vfold_cv(kids, v = rho, repeats = 10)
# Calculate the true overall mean
true <- mean(kids$ASER4)
ggreg_error <- function(splits){
# note that I treat the assessment data as the training data.
# this is because I want to fit the data on the 1/rho share of the data that is in the assessment data
sample <- assessment(splits)
other <- analysis(splits)
mod <- glm(rx, data = sample, family = binomial(link = "probit"))
#mod <- lm(rx, data = sample)
# fit the model to both the sample and the rest of the data
preds_other <- augment(mod, newdata = other, type.predict = "response")
preds_sample <- augment(mod, newdata = sample, type.predict = "response")
# Calculate the generalized GREG (see Pfefferman eq 4.8 for details)
ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE)/rho - mean(preds_sample$.fitted, na.rm = TRUE)/rho
# ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE) - mean(preds_sample$.fitted, na.rm = TRUE)
return(list(true-ggreg, true- mean(sample$ASER4, na.rm=TRUE)))
}
split_obj$error <- map(split_obj$splits, ggreg_error)
ggreg_error_vec <- map_dbl(split_obj$error, 1)
simple_error_vec <- map_dbl(split_obj$error, 2)
sqrt_mse_ggreg <- (mean(ggreg_error_vec^2))^.5
sqrt_mse_ggreg
sqrt_mse_simple <- (mean(simple_error_vec^2))^.5
sqrt_mse_simple
# Create new variables and drop everything else
kids <- ihds %>%
filter(!is.na(TA8B)) %>%
transmute(ASER4, TA4, RO3, URBAN2011, ASSETS, log_inc = log(INCOME+1), group = as_factor(GROUPS), RO5, HHEDUC, NPERSONS, log_pcc = log(COPC), private = ifelse((CS4 ==4), 1, 0))
rx <- as.formula("ASER4 ~ TA4 + log_pcc + RO3 + RO5 + HHEDUC + private + NPERSONS + URBAN2011 + log_inc + group")
rho <- 20
set.seed(123)
split_obj <- vfold_cv(kids, v = rho, repeats = 10)
# Calculate the true overall mean
true <- mean(kids$ASER4)
ggreg_error <- function(splits){
# note that I treat the assessment data as the training data.
# this is because I want to fit the data on the 1/rho share of the data that is in the assessment data
sample <- assessment(splits)
other <- analysis(splits)
mod <- glm(rx, data = sample, family = binomial(link = "probit"))
#mod <- lm(rx, data = sample)
# fit the model to both the sample and the rest of the data
preds_other <- augment(mod, newdata = other, type.predict = "response")
preds_sample <- augment(mod, newdata = sample, type.predict = "response")
# Calculate the generalized GREG (see Pfefferman eq 4.8 for details)
ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE)/rho - mean(preds_sample$.fitted, na.rm = TRUE)/rho
# ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE) - mean(preds_sample$.fitted, na.rm = TRUE)
return(list(true-ggreg, true- mean(sample$ASER4, na.rm=TRUE)))
}
split_obj$error <- map(split_obj$splits, ggreg_error)
ggreg_error_vec <- map_dbl(split_obj$error, 1)
simple_error_vec <- map_dbl(split_obj$error, 2)
sqrt_mse_ggreg <- (mean(ggreg_error_vec^2))^.5
sqrt_mse_ggreg
sqrt_mse_simple <- (mean(simple_error_vec^2))^.5
sqrt_mse_simple
# Create new variables and drop everything else
kids <- ihds %>%
filter(!is.na(TA8B)) %>%
transmute(ASER4, TA4, RO3, URBAN2011, ASSETS, log_inc = log(INCOME+1), group = as_factor(GROUPS), RO5, HHEDUC, NPERSONS, log_pcc = log(COPC), private = ifelse((CS4 ==4), 1, 0))
rx <- as.formula("ASER4 ~ TA4 + log_pcc + RO3 + RO5 + HHEDUC + private + NPERSONS + URBAN2011 + log_inc + group")
rho <- 20
set.seed(1234)
split_obj <- vfold_cv(kids, v = rho, repeats = 10)
# Calculate the true overall mean
true <- mean(kids$ASER4)
ggreg_error <- function(splits){
# note that I treat the assessment data as the training data.
# this is because I want to fit the data on the 1/rho share of the data that is in the assessment data
sample <- assessment(splits)
other <- analysis(splits)
mod <- glm(rx, data = sample, family = binomial(link = "probit"))
#mod <- lm(rx, data = sample)
# fit the model to both the sample and the rest of the data
preds_other <- augment(mod, newdata = other, type.predict = "response")
preds_sample <- augment(mod, newdata = sample, type.predict = "response")
# Calculate the generalized GREG (see Pfefferman eq 4.8 for details)
ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE)/rho - mean(preds_sample$.fitted, na.rm = TRUE)/rho
# ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE) - mean(preds_sample$.fitted, na.rm = TRUE)
return(list(true-ggreg, true- mean(sample$ASER4, na.rm=TRUE)))
}
split_obj$error <- map(split_obj$splits, ggreg_error)
# Create new variables and drop everything else
kids <- ihds %>%
filter(!is.na(TA8B)) %>%
transmute(ASER4, TA4, RO3, URBAN2011, ASSETS, log_inc = log(INCOME+1), group = as_factor(GROUPS), RO5, HHEDUC, NPERSONS, log_pcc = log(COPC), private = ifelse((CS4 ==4), 1, 0))
rx <- as.formula("ASER4 ~ TA4 + log_pcc + RO3 + RO5 + HHEDUC + private + NPERSONS + URBAN2011 + log_inc + group")
rho <- 20
set.seed(1234)
split_obj <- vfold_cv(kids, v = rho, repeats = 10)
# Calculate the true overall mean
true <- mean(kids$ASER4)
ggreg_error <- function(splits){
# note that I treat the assessment data as the training data.
# this is because I want to fit the data on the 1/rho share of the data that is in the assessment data
sample <- assessment(splits)
other <- analysis(splits)
mod <- glm(rx, data = sample, family = binomial(link = "probit"))
#mod <- lm(rx, data = sample)
# fit the model to both the sample and the rest of the data
preds_other <- augment(mod, newdata = other, type.predict = "response")
preds_sample <- augment(mod, newdata = sample, type.predict = "response")
# Calculate the generalized GREG (see Pfefferman eq 4.8 for details)
ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE)/rho - mean(preds_sample$.fitted, na.rm = TRUE)/rho
# ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE) - mean(preds_sample$.fitted, na.rm = TRUE)
return(list(true-ggreg, true- mean(sample$ASER4, na.rm=TRUE)))
}
split_obj$error <- map(split_obj$splits, ggreg_error)
# Create new variables and drop everything else
kids <- ihds %>%
filter(!is.na(TA8B)) %>%
transmute(ASER4, TA4, RO3, URBAN2011, ASSETS, log_inc = log(INCOME+1), group = as_factor(GROUPS), RO5, HHEDUC, NPERSONS, log_pcc = log(COPC), private = ifelse((CS4 ==4), 1, 0))
rx <- as.formula("ASER4 ~ TA4 + log_pcc + RO3 + RO5 + HHEDUC + private + NPERSONS + URBAN2011 + log_inc + group")
rho <- 20
set.seed(12345)
split_obj <- vfold_cv(kids, v = rho, repeats = 10)
# Calculate the true overall mean
true <- mean(kids$ASER4)
ggreg_error <- function(splits){
# note that I treat the assessment data as the training data.
# this is because I want to fit the data on the 1/rho share of the data that is in the assessment data
sample <- assessment(splits)
other <- analysis(splits)
mod <- glm(rx, data = sample, family = binomial(link = "probit"))
#mod <- lm(rx, data = sample)
# fit the model to both the sample and the rest of the data
preds_other <- augment(mod, newdata = other, type.predict = "response")
preds_sample <- augment(mod, newdata = sample, type.predict = "response")
# Calculate the generalized GREG (see Pfefferman eq 4.8 for details)
ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE)/rho - mean(preds_sample$.fitted, na.rm = TRUE)/rho
# ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE) - mean(preds_sample$.fitted, na.rm = TRUE)
return(list(true-ggreg, true- mean(sample$ASER4, na.rm=TRUE)))
}
split_obj$error <- map(split_obj$splits, ggreg_error)
ggreg_error_vec <- map_dbl(split_obj$error, 1)
simple_error_vec <- map_dbl(split_obj$error, 2)
sqrt_mse_ggreg <- (mean(ggreg_error_vec^2))^.5
sqrt_mse_ggreg
sqrt_mse_simple <- (mean(simple_error_vec^2))^.5
sqrt_mse_simple
# Create new variables and drop everything else
kids <- ihds %>%
filter(!is.na(TA8B)) %>%
transmute(ASER4, TA4, RO3, URBAN2011, ASSETS, log_inc = log(INCOME+1), group = as_factor(GROUPS), RO5, HHEDUC, NPERSONS, log_pcc = log(COPC), private = ifelse((CS4 ==4), 1, 0))
rx <- as.formula("ASER4 ~ TA4 + log_pcc + RO3 + RO5 + HHEDUC + private + NPERSONS + URBAN2011 + log_inc + group")
rho <- 20
set.seed(123456)
split_obj <- vfold_cv(kids, v = rho, repeats = 10)
# Calculate the true overall mean
true <- mean(kids$ASER4)
ggreg_error <- function(splits){
# note that I treat the assessment data as the training data.
# this is because I want to fit the data on the 1/rho share of the data that is in the assessment data
sample <- assessment(splits)
other <- analysis(splits)
mod <- glm(rx, data = sample, family = binomial(link = "probit"))
#mod <- lm(rx, data = sample)
# fit the model to both the sample and the rest of the data
preds_other <- augment(mod, newdata = other, type.predict = "response")
preds_sample <- augment(mod, newdata = sample, type.predict = "response")
# Calculate the generalized GREG (see Pfefferman eq 4.8 for details)
ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE)/rho - mean(preds_sample$.fitted, na.rm = TRUE)/rho
# ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE) - mean(preds_sample$.fitted, na.rm = TRUE)
return(list(true-ggreg, true- mean(sample$ASER4, na.rm=TRUE)))
}
split_obj$error <- map(split_obj$splits, ggreg_error)
ggreg_error_vec <- map_dbl(split_obj$error, 1)
simple_error_vec <- map_dbl(split_obj$error, 2)
sqrt_mse_ggreg <- (mean(ggreg_error_vec^2))^.5
sqrt_mse_ggreg
sqrt_mse_simple <- (mean(simple_error_vec^2))^.5
sqrt_mse_simple
# Create new variables and drop everything else
kids <- ihds %>%
filter(!is.na(TA8B)) %>%
transmute(ASER4, TA4, RO3, URBAN2011, ASSETS, log_inc = log(INCOME+1), group = as_factor(GROUPS), RO5, HHEDUC, NPERSONS, log_pcc = log(COPC), private = ifelse((CS4 ==4), 1, 0))
rx <- as.formula("ASER4 ~ TA4 + log_pcc + RO3 + RO5 + HHEDUC + private + NPERSONS + URBAN2011 + log_inc + group")
rho <- 20
set.seed(1234567)
split_obj <- vfold_cv(kids, v = rho, repeats = 10)
# Calculate the true overall mean
true <- mean(kids$ASER4)
ggreg_error <- function(splits){
# note that I treat the assessment data as the training data.
# this is because I want to fit the data on the 1/rho share of the data that is in the assessment data
sample <- assessment(splits)
other <- analysis(splits)
mod <- glm(rx, data = sample, family = binomial(link = "probit"))
#mod <- lm(rx, data = sample)
# fit the model to both the sample and the rest of the data
preds_other <- augment(mod, newdata = other, type.predict = "response")
preds_sample <- augment(mod, newdata = sample, type.predict = "response")
# Calculate the generalized GREG (see Pfefferman eq 4.8 for details)
ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE)/rho - mean(preds_sample$.fitted, na.rm = TRUE)/rho
# ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE) - mean(preds_sample$.fitted, na.rm = TRUE)
return(list(true-ggreg, true- mean(sample$ASER4, na.rm=TRUE)))
}
split_obj$error <- map(split_obj$splits, ggreg_error)
ggreg_error_vec <- map_dbl(split_obj$error, 1)
simple_error_vec <- map_dbl(split_obj$error, 2)
sqrt_mse_ggreg <- (mean(ggreg_error_vec^2))^.5
sqrt_mse_ggreg
sqrt_mse_simple <- (mean(simple_error_vec^2))^.5
sqrt_mse_simple
# Create new variables and drop everything else
kids <- ihds %>%
filter(!is.na(TA8B)) %>%
transmute(ASER4, TA4, RO3, URBAN2011, ASSETS, log_inc = log(INCOME+1), group = as_factor(GROUPS), RO5, HHEDUC, NPERSONS, log_pcc = log(COPC), private = ifelse((CS4 ==4), 1, 0))
rx <- as.formula("ASER4 ~ TA4 + log_pcc + RO3 + RO5 + HHEDUC + private + NPERSONS + URBAN2011 + log_inc + group")
rho <- 20
set.seed(12345678)
split_obj <- vfold_cv(kids, v = rho, repeats = 10)
# Calculate the true overall mean
true <- mean(kids$ASER4)
ggreg_error <- function(splits){
# note that I treat the assessment data as the training data.
# this is because I want to fit the data on the 1/rho share of the data that is in the assessment data
sample <- assessment(splits)
other <- analysis(splits)
mod <- glm(rx, data = sample, family = binomial(link = "probit"))
#mod <- lm(rx, data = sample)
# fit the model to both the sample and the rest of the data
preds_other <- augment(mod, newdata = other, type.predict = "response")
preds_sample <- augment(mod, newdata = sample, type.predict = "response")
# Calculate the generalized GREG (see Pfefferman eq 4.8 for details)
ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE)/rho - mean(preds_sample$.fitted, na.rm = TRUE)/rho
# ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE) - mean(preds_sample$.fitted, na.rm = TRUE)
return(list(true-ggreg, true- mean(sample$ASER4, na.rm=TRUE)))
}
split_obj$error <- map(split_obj$splits, ggreg_error)
ggreg_error_vec <- map_dbl(split_obj$error, 1)
simple_error_vec <- map_dbl(split_obj$error, 2)
sqrt_mse_ggreg <- (mean(ggreg_error_vec^2))^.5
sqrt_mse_ggreg
sqrt_mse_simple <- (mean(simple_error_vec^2))^.5
sqrt_mse_simple
# Create new variables and drop everything else
kids <- ihds %>%
filter(!is.na(TA8B)) %>%
transmute(ASER4, TA4, RO3, URBAN2011, ASSETS, log_inc = log(INCOME+1), group = as_factor(GROUPS), RO5, HHEDUC, NPERSONS, log_pcc = log(COPC), private = ifelse((CS4 ==4), 1, 0))
rx <- as.formula("ASER4 ~ TA4 + log_pcc + RO3 + RO5 + HHEDUC + private + NPERSONS + URBAN2011 + log_inc + group")
rho <- 20
set.seed(123456789)
split_obj <- vfold_cv(kids, v = rho, repeats = 10)
# Calculate the true overall mean
true <- mean(kids$ASER4)
ggreg_error <- function(splits){
# note that I treat the assessment data as the training data.
# this is because I want to fit the data on the 1/rho share of the data that is in the assessment data
sample <- assessment(splits)
other <- analysis(splits)
mod <- glm(rx, data = sample, family = binomial(link = "probit"))
#mod <- lm(rx, data = sample)
# fit the model to both the sample and the rest of the data
preds_other <- augment(mod, newdata = other, type.predict = "response")
preds_sample <- augment(mod, newdata = sample, type.predict = "response")
# Calculate the generalized GREG (see Pfefferman eq 4.8 for details)
ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE)/rho - mean(preds_sample$.fitted, na.rm = TRUE)/rho
# ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE) - mean(preds_sample$.fitted, na.rm = TRUE)
return(list(true-ggreg, true- mean(sample$ASER4, na.rm=TRUE)))
}
split_obj$error <- map(split_obj$splits, ggreg_error)
ggreg_error_vec <- map_dbl(split_obj$error, 1)
simple_error_vec <- map_dbl(split_obj$error, 2)
sqrt_mse_ggreg <- (mean(ggreg_error_vec^2))^.5
sqrt_mse_ggreg
sqrt_mse_simple <- (mean(simple_error_vec^2))^.5
sqrt_mse_simple
blogdown:::serve_site()
?unnest
sqrt_mse_ggreg
?unnest
?unest
# Create a new dataframe with only children 8-11 and all the variables we want to use in our analysis
kids <- ihds %>%
filter(!is.na(TA8B)) %>%
transmute(ASER4, TA4, RO3, URBAN2011, ASSETS, log_inc = log(INCOME+1), group = as_factor(GROUPS), RO5, HHEDUC, NPERSONS, log_pcc = log(COPC), private = ifelse((CS4 ==4), 1, 0))
# Load required pacakges
library(tidyverse); library(survey); library(haven); library(tidymodels)
# Load the Stata version of the individual level IHDS file
# To get this file go to https://www.icpsr.umich.edu/web/DSDR/studies/36151
# Then click "download" and "stata". You will need to create a login and you will get a bunch of other files in addition to this one.
ihds_ind_dir <- "C:/Users/dougj/Documents/Data/IHDS/IHDS 2012/DS0001"
ind_file <- file.path(ihds_ind_dir, "36151-0001-Data.dta")
ihds <- read_dta(ind_file, col_select = c(STATEID, DISTID, PSUID, URBAN2011, HHID, HHSPLITID, PERSONID, IDPSU, WT, RO3, RO7, RO5, COPC, ASSETS, GROUPS, HHEDUC, HHEDUCM, HHEDUCF, INCOME, NPERSONS,starts_with("CS"), starts_with("TA"), starts_with("ED")))
# Create variables for full PSU ID, HH ID, ASER score, and state
ihds <- ihds %>%
mutate(psu_expanded = paste(STATEID, DISTID, PSUID, sep ="-"),
hh_expanded = paste(STATEID, DISTID, PSUID, HHID, HHSPLITID, sep ="-"),
ASER4 = (TA8B ==4),
State = as_factor(STATEID)) %>%
filter(!is.na(WT))
# Specify the survey design
# note that this and the line after can take a minute or two
ihds_svy <- svydesign(id =~ psu_expanded + hh_expanded, weights =~ WT, data = ihds)
# Estimate the mean of ASER4 for the full country and get the standard error
svymean(~ASER4, ihds_svy, na.rm =TRUE)
# Create a new dataframe with only children 8-11 and all the variables we want to use in our analysis
kids <- ihds %>%
filter(!is.na(TA8B)) %>%
transmute(ASER4, TA4, RO3, URBAN2011, ASSETS, log_inc = log(INCOME+1), group = as_factor(GROUPS), RO5, HHEDUC, NPERSONS, log_pcc = log(COPC), private = ifelse((CS4 ==4), 1, 0))
# Create a formula that we will use in our probit regression later
rx <- as.formula("ASER4 ~ TA4 + log_pcc + RO3 + RO5 + HHEDUC + private + NPERSONS + URBAN2011 + log_inc + group")
# 1/rho is the proportion of the main sample that we assume will be sub-sampled
rho <- 20
# set the seed so this is reproducible
set.seed(123456789)
# Create a 20-fold split
split_obj <- vfold_cv(kids, v = rho, repeats = 10)
# Calculate the true overall mean
true <- mean(kids$ASER4)
# Create a function which will take one of the splits from the split_obj and calculate
# the error assuming we don't use an auxiliary info and using auxiliary information.
# See here for more info https://rsample.tidymodels.org/articles/Working_with_rsets.html
ggreg_error <- function(splits){
# Please note that I use the assessment data as the training data and the analysis test
# as the holdout data.  This is the exact opposite of what a normal ML work flow looks like.
# In a normal workflow, you fit your model on the 1-1/rho of the data and
#then test it on the 1/rho portion of the data.  I want to do the exact opposite.
sample <- assessment(splits)
other <- analysis(splits)
# Fit the model
mod <- glm(rx, data = sample, family = binomial(link = "probit"))
# Generate model predictions for both datasets
preds_other <- augment(mod, newdata = other, type.predict = "response")
preds_sample <- augment(mod, newdata = sample, type.predict = "response")
# Calculate the generalized GREG (see Pfefferman eq 4.8 for details)
ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE)/rho - mean(preds_sample$.fitted, na.rm = TRUE)/rho
# Return
return(list(true-ggreg, true- mean(sample$ASER4, na.rm=TRUE)))
}
split_obj$error <- map(split_obj$splits, ggreg_error)
ggreg_error_vec <- map_dbl(split_obj$error, 1)
simple_error_vec <- map_dbl(split_obj$error, 2)
sqrt_mse_ggreg <- (mean(ggreg_error_vec^2))^.5
sqrt_mse_ggreg
sqrt_mse_simple <- (mean(simple_error_vec^2))^.5
sqrt_mse_simple
unnet(split)
unnet(split_obj)
unnest(split_obj)
?unnest
temp <- unnest(split_obj, cols = "error")
temp
# Create a new dataframe with only children 8-11 and all the variables we want to use in our analysis
kids <- ihds %>%
filter(!is.na(TA8B)) %>%
transmute(ASER4, TA4, RO3, URBAN2011, ASSETS, log_inc = log(INCOME+1), group = as_factor(GROUPS), RO5, HHEDUC, NPERSONS, log_pcc = log(COPC), private = ifelse((CS4 ==4), 1, 0))
# Create a formula that we will use in our probit regression later
rx <- as.formula("ASER4 ~ TA4 + log_pcc + RO3 + RO5 + HHEDUC + private + NPERSONS + URBAN2011 + log_inc + group")
# 1/rho is the proportion of the main sample that we assume will be sub-sampled
rho <- 20
# set the seed so this is reproducible
set.seed(123456789)
# Create a 20-fold split
split_obj <- vfold_cv(kids, v = rho, repeats = 10)
# Calculate the true overall mean
true <- mean(kids$ASER4)
# Create a function which will take one of the splits from the split_obj and calculate
# the error assuming we don't use an auxiliary info and using auxiliary information.
# See here for more info https://rsample.tidymodels.org/articles/Working_with_rsets.html
ggreg_error <- function(splits){
# Please note that I use the assessment data as the training data and the analysis test
# as the holdout data.  This is the exact opposite of what a normal ML work flow looks like.
# In a normal workflow, you fit your model on the 1-1/rho of the data and
#then test it on the 1/rho portion of the data.  I want to do the exact opposite.
sample <- assessment(splits)
other <- analysis(splits)
# Fit the model
mod <- glm(rx, data = sample, family = binomial(link = "probit"))
# Generate model predictions for both datasets
preds_other <- augment(mod, newdata = other, type.predict = "response")
preds_sample <- augment(mod, newdata = sample, type.predict = "response")
# Calculate the generalized GREG (see Pfefferman eq 4.8 for details)
ggreg <- mean(preds_other$.fitted, na.rm = TRUE) + mean(sample$ASER4, na.rm = TRUE)/rho - mean(preds_sample$.fitted, na.rm = TRUE)/rho
# Return
return(list(true-ggreg, true- mean(sample$ASER4, na.rm=TRUE)))
}
# Map this function to the split object
split_obj$error <- map(split_obj$splits, ggreg_error)
# Get the root mean squared error for both the simple mean and the generalized GREG estimator
ggreg_error_vec <- map_dbl(split_obj$error, 1)
simple_error_vec <- map_dbl(split_obj$error, 2)
sqrt_mse_ggreg <- (mean(ggreg_error_vec^2))^.5
sqrt_mse_ggreg
sqrt_mse_simple <- (mean(simple_error_vec^2))^.5
sqrt_mse_simple
sqrt_mse_ggreg
sqrt_mse_simple
(.01^2+.02^2)^.5
(.08^2+.02^2)^.5
(.008^2+.02^2)^.5
nrow(kids)
nrow(kids)/20
(.35*.65)/600^.5
((.35*.65)/600)^.5
blogdown:::serve_site()
sqrt_mse_ggreg
(.0084^2+.0196^2)^.5

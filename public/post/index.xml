<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Doug Johnson&#39;s website</title>
    <link>/post/</link>
    <description>Recent content in Posts on Doug Johnson&#39;s website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>&amp;copy; &lt;a href=&#34;https://github.com/dougj892&#34;&gt;Doug Johnson&lt;/a&gt; 2020. Site design by &lt;a href=&#34;https://github.com/ribic&#34;&gt;Emir Ribic</copyright>
    <lastBuildDate>Sun, 12 Jul 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>School versus household based surveys for collecting learning outcomes data</title>
      <link>/post/school-versus-household-based-surveys-for-collecting-learning-outcomes-data/</link>
      <pubDate>Sun, 12 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/school-versus-household-based-surveys-for-collecting-learning-outcomes-data/</guid>
      <description>I recently wrote a working paper in which I look at the reliability of learning outcomes data in India. (I’ll add the link soon.) The main findings of the paper are a) the government-run survey of learning outcomes (called the NAS) likely contains a lot of noise and b) the main independent survey of learning outcomes (ASER) is a tad bit noisier than the survey’s sample size would lead one to believe.</description>
    </item>
    
    <item>
      <title>Why I support same language subtiting</title>
      <link>/post/why-i-support-same-language-subtiting/</link>
      <pubDate>Sun, 07 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/why-i-support-same-language-subtiting/</guid>
      <description>In the fall, India’s ministry of information and broadcasting announced that it would require all major TV channels to add “same language subtitles” (SLS) – i.e. subtitles in the same language as the content to the programming. The rules stipulate that channels must have at least one program with subtitles in 2019 and ramp up to 50% of programming with subtitles by 2025.
The motivation for the rule is that it will (hopefully) help children learn to read.</description>
    </item>
    
    <item>
      <title>Did same language subtitling increase reading levels in Maharashtra?</title>
      <link>/post/same-language-subtitling/</link>
      <pubDate>Tue, 02 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/same-language-subtitling/</guid>
      <description>TLDR: Maybe, but we can’t say much from the data. In my next blog post, I argue that we should fund SLS anyway.
SummaryBetween 2013 and 2015, Zee Talkies, with the support of PlanetRead and USAID, added subtitles to all of the songs of many of the Marathi movies it broadcast. The organizers of the project hoped that by adding the subtitles, a strategy known as “same language subtitling,” they would get children to read along as they listened to the songs and thus improve their reading skills.</description>
    </item>
    
    <item>
      <title>Why India Should Focus on Educational TV rather than EdTech</title>
      <link>/post/why-india-should-focus-on-educational-tv-rather-than-edtech/</link>
      <pubDate>Tue, 26 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/why-india-should-focus-on-educational-tv-rather-than-edtech/</guid>
      <description>A couple of weeks ago, Rob Sampson and I published an op-ed in Quartz India arguing that the central and state governments in India should use Educational TV rather than smartphone-based EdTech to reach students out of school due to the covid crisis. We use survey data to show that smartphone penetration in India is much lower than sales figures would lead you to believe. By contrast, TV ownership is relatively high even among the poor.</description>
    </item>
    
    <item>
      <title>Estimating seroprevalence with data from an imperfect test on a convenience sample</title>
      <link>/post/estimating-seroprevalence-with-data-from-an-imperfect-test-on-a-convenience-sample/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/estimating-seroprevalence-with-data-from-an-imperfect-test-on-a-convenience-sample/</guid>
      <description>Several recent studies have used data from antibody tests performed on a convenience sample to estimate seroprevalence of covid 19 in a population. Estimating seroprevalence from this data presents two challenges. First, the analyst must take steps, through weighting or other measures, to deal with likely sample selection bias. Second, the analyst must take into account imperfections in the test itself.
Addressing either of these challenges on their own is relatively straightforward to do using existing tools.</description>
    </item>
    
    <item>
      <title>An Alternative Approach to Power Calculations</title>
      <link>/post/an-alternative-approach-to-power-calculations/</link>
      <pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/an-alternative-approach-to-power-calculations/</guid>
      <description>The typical approach to power calculations goes something like this: first, the evaluator estimates the smallest MDE for which the intervention would be cost-effective. Second, the evaluator calculates the sample required to detect that MDE. Third, the evaluator throws out the calculations from step two after realizing the evaluation would be way too expensive and instead estimates the MDE she can detect given her budget constraints.The problem with this approach is that it doesn’t take into account the cost of the evaluation itself.</description>
    </item>
    
    <item>
      <title>Calculating Covid Prevalence from Antibody Tests</title>
      <link>/post/calculating-covid-prevalence-from-antibody-tests/</link>
      <pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/calculating-covid-prevalence-from-antibody-tests/</guid>
      <description>A group of Stanford researchers recently published two studies which estimated the prevalence of covid in two counties of California using antibody tests. The studies faced a lot of criticism by stats folks around the web.
The criticism appears well deserved but in all of the criticism, I didn’t come across much in the way of clear advice on how they could account for potential diagnostic test errors better. (The post by Andrew Gelman linked to above has a lot of useful advice on other aspects of the study but was a little quiet on this subject.</description>
    </item>
    
    <item>
      <title>Three Stage Sampling</title>
      <link>/post/3-stage/</link>
      <pubDate>Wed, 04 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/3-stage/</guid>
      <description>Caveat emptor: This blog post has not been thoroughly checked for errors.
One of IDinsight&amp;rsquo;s project teams is in the process of designing the sampling strategy for a large scale household survey and is considering using a three stage sampling design in which they would first select districts, then villages (or urban wards), and then households. In addition, someone was asking about three stage clustering for an RCT somewhere on Slack (I can&amp;rsquo;t seem to find the slack post now) so I thought it might be useful to write a short post on three stage designs.</description>
    </item>
    
    <item>
      <title>Simple Random Sampling vs. PPS Sampling</title>
      <link>/post/srs-v-pps/</link>
      <pubDate>Fri, 21 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/srs-v-pps/</guid>
      <description>A question came up on one of our evaluations on whether we should use simple random sampling (SRS) or probability proportional to size (PPS) sampling when selecting villages (our primary sampling units) for a matching study. Under SRS, you randomly select primary sampling units (PSUs) until you reach your desired sample size. With PPS sampling, you select your PSUs using some measure of size. PPS is often used in a first stage of a two-stage sampling design because if you use PPS to select PSUs and then select a fixed number of units (households in our case) per PSU in the second stage of sampling, the probability of selection will be identical for all units.</description>
    </item>
    
    <item>
      <title>Fixed Effects vs Difference-in-Differences</title>
      <link>/post/fe-did/</link>
      <pubDate>Wed, 15 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/fe-did/</guid>
      <description>TL;DR: When you have longitudinal data, you should use fixed effects or ANCOVA rather than difference-in-differences since a difference-in-difference specification will spit out incorrect variance estimates. If the data is from a randomized trial, ANCOVA is probably a better bet.
Trying to understand when to use fixed effects and when to use difference-in-differences (DiD), in the past, always made me feel like an idiot. It seemed like I was missing something really obvious that everyone else was getting.</description>
    </item>
    
    <item>
      <title>Web Scraping 101</title>
      <link>/post/web-scraping/</link>
      <pubDate>Wed, 31 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/web-scraping/</guid>
      <description>More and more organizations are publishing their data on the web. This is great, but often websites don’t offer an option to download a clean and complete dataset from the site. In this situation, you have two options. First, you (or some unlucky intern) can hunker down and spend a week wearing out the ‘c’ and ‘v’ keys on your keyboard as you cut and paste ad nauseam from the website to an Excel spreadsheet.</description>
    </item>
    
    <item>
      <title>Multiple Hypothesis Testing</title>
      <link>/post/mult-hypothesis/</link>
      <pubDate>Mon, 04 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/mult-hypothesis/</guid>
      <description>layout: post title: &amp;ldquo;Multiple Hypothesis Testing&amp;rdquo; date: 2016-07-04 10:40:48 -0400 categories: jekyll update This week, I volunteered to read and summarize one of the articles for IDinsigh&amp;rsquo;s tech team&amp;rsquo;s book club. The topic for this week is multiple hypothesis testing and the article I volunteered to summarize is &amp;ldquo;Multiple Inference and Gender Differences in the Effects of Early Intervention: A Reevaluation of the Abecedarian, Perry Preschool, and Early Training Projects&amp;rdquo; by Michael Anderson.</description>
    </item>
    
    <item>
      <title>Response to Blattman&#39;s Post on Why What Works Is The Wrong Question</title>
      <link>/post/blattman/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/post/blattman/</guid>
      <description>Last week, Chris Blattman published a long blog post titled “Why ‘what works?’ is the wrong question: evaluating ideas not programs.” In the blog post, which was adapted from a talk he gave at DFID, Blattman argues that a) impact evaluations should focus on deeper, theory-driven questions rather than just whether a program works or not and b) researchers should design impact evaluations to allow for generalizability by paying attention to context and running multiple evaluations in multiple contexts.</description>
    </item>
    
  </channel>
</rss>